{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ded6b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data preparation & visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"png\"\n",
    "\n",
    "# Ignore printing warnings for general readability\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# pip install scikit-surprise\n",
    "# Importing libraries for model building & evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from surprise import KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline\n",
    "from surprise import accuracy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad1c63aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset \n",
    "def loaddata(filename):\n",
    "    df = pd.read_csv(f'{filename}.csv',sep=';',error_bad_lines=False,warn_bad_lines=False,encoding='latin-1')\n",
    "    return df\n",
    "\n",
    "book   = loaddata(\"../../BX-Books\")\n",
    "user   = loaddata(\"../../BX-Users\")\n",
    "rating = loaddata(\"../../BX-Book-Ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "863e1e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>277427</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>277427</td>\n",
       "      <td>006092988X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>277427</td>\n",
       "      <td>0060930535</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>277427</td>\n",
       "      <td>0060932139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>277427</td>\n",
       "      <td>0060934417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147440</th>\n",
       "      <td>275970</td>\n",
       "      <td>1400031354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147441</th>\n",
       "      <td>275970</td>\n",
       "      <td>1400031362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147470</th>\n",
       "      <td>275970</td>\n",
       "      <td>1558744606</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147517</th>\n",
       "      <td>275970</td>\n",
       "      <td>1573229725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147584</th>\n",
       "      <td>275970</td>\n",
       "      <td>1853260010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81431 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         User-ID        ISBN  Book-Rating\n",
       "1456      277427  002542730X           10\n",
       "1468      277427  006092988X            0\n",
       "1469      277427  0060930535            0\n",
       "1470      277427  0060932139            0\n",
       "1471      277427  0060934417            0\n",
       "...          ...         ...          ...\n",
       "1147440   275970  1400031354            0\n",
       "1147441   275970  1400031362            0\n",
       "1147470   275970  1558744606            0\n",
       "1147517   275970  1573229725            0\n",
       "1147584   275970  1853260010            0\n",
       "\n",
       "[81431 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_users = rating['User-ID'].value_counts().reset_index().\\\n",
    "               rename({'Index':'User-ID','User-ID':'Rating'}, axis=1)\n",
    "rating_books = rating['ISBN'].value_counts().reset_index().\\\n",
    "               rename({'Index':'ISBN','ISBN':'Rating'}, axis=1)\n",
    "# In order to avoid rating bias & for making good recommendations, limit the dataset to only those\n",
    "# users that have made at least 250 ratings & books that have received at least 50 ratings\n",
    "\n",
    "rating = rating[rating['User-ID'].isin(rating_users[rating_users['Rating']>=250]['index'])]\n",
    "rating = rating[rating['ISBN'].isin(rating_books[rating_books['Rating']>=50]['index'])]\n",
    "\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acc1c4fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>277427</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>10</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3363</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>0</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11676</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>6</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12538</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>10</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13552</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>0</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80889</th>\n",
       "      <td>234828</td>\n",
       "      <td>0345333926</td>\n",
       "      <td>8</td>\n",
       "      <td>Ringworld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80890</th>\n",
       "      <td>236283</td>\n",
       "      <td>0345333926</td>\n",
       "      <td>0</td>\n",
       "      <td>Ringworld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80891</th>\n",
       "      <td>249628</td>\n",
       "      <td>0345333926</td>\n",
       "      <td>0</td>\n",
       "      <td>Ringworld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80892</th>\n",
       "      <td>261829</td>\n",
       "      <td>0345333926</td>\n",
       "      <td>0</td>\n",
       "      <td>Ringworld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80893</th>\n",
       "      <td>264321</td>\n",
       "      <td>0345333926</td>\n",
       "      <td>8</td>\n",
       "      <td>Ringworld</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80894 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       User-ID        ISBN  Book-Rating  \\\n",
       "0       277427  002542730X           10   \n",
       "1         3363  002542730X            0   \n",
       "2        11676  002542730X            6   \n",
       "3        12538  002542730X           10   \n",
       "4        13552  002542730X            0   \n",
       "...        ...         ...          ...   \n",
       "80889   234828  0345333926            8   \n",
       "80890   236283  0345333926            0   \n",
       "80891   249628  0345333926            0   \n",
       "80892   261829  0345333926            0   \n",
       "80893   264321  0345333926            8   \n",
       "\n",
       "                                              Book-Title  \n",
       "0      Politically Correct Bedtime Stories: Modern Ta...  \n",
       "1      Politically Correct Bedtime Stories: Modern Ta...  \n",
       "2      Politically Correct Bedtime Stories: Modern Ta...  \n",
       "3      Politically Correct Bedtime Stories: Modern Ta...  \n",
       "4      Politically Correct Bedtime Stories: Modern Ta...  \n",
       "...                                                  ...  \n",
       "80889                                          Ringworld  \n",
       "80890                                          Ringworld  \n",
       "80891                                          Ringworld  \n",
       "80892                                          Ringworld  \n",
       "80893                                          Ringworld  \n",
       "\n",
       "[80894 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the recommendation system, it is prefered to have the book titles rather than ISBN for easier interpretation\n",
    "\n",
    "rating = rating.merge(book, on=\"ISBN\")[['User-ID','ISBN','Book-Rating','Book-Title']] # merging with the book dataframe\n",
    "rating    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd6f4bd",
   "metadata": {},
   "source": [
    "# Using surprise for data with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c3ee5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a surprise object\n",
    "\n",
    "reader = Reader(rating_scale=(0, 10))\n",
    "# data_nonzero   = Dataset.load_from_df(ratings_explicit[['User-ID','ISBN','Book-Rating']], reader)\n",
    "data  = Dataset.load_from_df(rating[['User-ID','ISBN','Book-Rating']], reader)\n",
    "\n",
    "\n",
    "# Split the data into training & testing sets. Python's surprise documentation has the steps detailed out\n",
    "# https://surprise.readthedocs.io/en/stable/FAQ.html\n",
    "\n",
    "raw_ratings = data.raw_ratings\n",
    "random.shuffle(raw_ratings)                 # shuffle dataset\n",
    "\n",
    "threshold   = int(len(raw_ratings)*0.8)\n",
    "\n",
    "train_raw_ratings = raw_ratings[:threshold] # 80% of data is trainset\n",
    "test_raw_ratings  = raw_ratings[threshold:] # 20% of data is testset\n",
    "\n",
    "data.raw_ratings = train_raw_ratings        # data is now the trainset\n",
    "trainset         = data.build_full_trainset() \n",
    "testset          = data.construct_testset(test_raw_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9174eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying KNN (K-Nearest Neighbors) & SVD (Singluar Value decomposition) algorithms using default model parameters\n",
    "\n",
    "models=[KNNBasic(),KNNWithMeans(),KNNWithZScore(),KNNBaseline()] \n",
    "results = {}\n",
    "\n",
    "for model in models:\n",
    "    # perform 5 fold cross validation\n",
    "    # evaluation metrics: mean absolute error & root mean square error\n",
    "    CV_scores = cross_validate(model, data, measures=[\"MAE\",\"RMSE\"], cv=5, n_jobs=-1)  \n",
    "    \n",
    "    # storing the average score across the 5 fold cross validation for each model\n",
    "    result = pd.DataFrame.from_dict(CV_scores).mean(axis=0).\\\n",
    "             rename({'test_mae':'MAE', 'test_rmse': 'RMSE'})\n",
    "    results[str(model).split(\"algorithms.\")[1].split(\"object \")[0]] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc411434",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knns.KNNWithMeans</th>\n",
       "      <td>2.345479</td>\n",
       "      <td>3.300367</td>\n",
       "      <td>0.116832</td>\n",
       "      <td>0.763151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knns.KNNBaseline</th>\n",
       "      <td>2.346841</td>\n",
       "      <td>3.301817</td>\n",
       "      <td>0.105052</td>\n",
       "      <td>1.070257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knns.KNNWithZScore</th>\n",
       "      <td>2.322376</td>\n",
       "      <td>3.331120</td>\n",
       "      <td>0.110006</td>\n",
       "      <td>0.856742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knns.KNNBasic</th>\n",
       "      <td>2.440255</td>\n",
       "      <td>3.515788</td>\n",
       "      <td>0.082228</td>\n",
       "      <td>0.668339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          MAE      RMSE  fit_time  test_time\n",
       "knns.KNNWithMeans    2.345479  3.300367  0.116832   0.763151\n",
       "knns.KNNBaseline     2.346841  3.301817  0.105052   1.070257\n",
       "knns.KNNWithZScore   2.322376  3.331120  0.110006   0.856742\n",
       "knns.KNNBasic        2.440255  3.515788  0.082228   0.668339"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df = pd.DataFrame.from_dict(results)\n",
    "print(\"Model Performance: \\n\")\n",
    "performance_df.T.sort_values(by='RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "755bf90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18651, 4)\n",
      "(62243, 4)\n"
     ]
    }
   ],
   "source": [
    "ratings_explicit=rating[rating['Book-Rating']!=0]\n",
    "ratings_implicit=rating[rating['Book-Rating']==0]\n",
    "print(ratings_explicit.shape)\n",
    "print(ratings_implicit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8085475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Best Parameters:  {'sim_options': {'name': 'pearson', 'min_support': 1, 'user_based': False}}\n",
      "MAE Best Score:       2.3245501488622944\n",
      "\n",
      "RMSE Best Parameters: {'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': False}}\n",
      "RMSE Best Score:      3.229344416698337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning - KNNWithMeans\n",
    "\n",
    "param_grid = { 'sim_options' : {'name': ['msd','pearson','pearson_baseline'], \\\n",
    "                                'min_support': [1,5], \\\n",
    "                                'user_based': [False, True]}\n",
    "             }\n",
    "\n",
    "gridsearchKNNWithMeans = GridSearchCV(KNNWithMeans, param_grid, measures=['mae', 'rmse'], \\\n",
    "                                      cv=5, n_jobs=-1)\n",
    "                                    \n",
    "gridsearchKNNWithMeans.fit(data)\n",
    "\n",
    "print(f'MAE Best Parameters:  {gridsearchKNNWithMeans.best_params[\"mae\"]}')\n",
    "print(f'MAE Best Score:       {gridsearchKNNWithMeans.best_score[\"mae\"]}\\n')\n",
    "\n",
    "print(f'RMSE Best Parameters: {gridsearchKNNWithMeans.best_params[\"rmse\"]}')\n",
    "print(f'RMSE Best Score:      {gridsearchKNNWithMeans.best_score[\"rmse\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a56e8e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Best Parameters:  {'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': False}}\n",
      "MAE Best Score:       2.2881471075654347\n",
      "\n",
      "RMSE Best Parameters: {'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': False}}\n",
      "RMSE Best Score:      3.2045208367297464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning - KNNBasic\n",
    "\n",
    "param_grid = { 'sim_options' : {'name': ['msd','pearson','pearson_baseline'], \\\n",
    "                                'min_support': [1,5], \\\n",
    "                                'user_based': [False, True]}\n",
    "             }\n",
    "\n",
    "gridsearchKNNBasic = GridSearchCV(KNNBasic, param_grid, measures=['mae', 'rmse'], \\\n",
    "                                      cv=5, n_jobs=-1)\n",
    "                                    \n",
    "gridsearchKNNBasic.fit(data)\n",
    "\n",
    "print(f'MAE Best Parameters:  {gridsearchKNNBasic.best_params[\"mae\"]}')\n",
    "print(f'MAE Best Score:       {gridsearchKNNBasic.best_score[\"mae\"]}\\n')\n",
    "\n",
    "print(f'RMSE Best Parameters: {gridsearchKNNBasic.best_params[\"rmse\"]}')\n",
    "print(f'RMSE Best Score:      {gridsearchKNNBasic.best_score[\"rmse\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7002b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Best Parameters:  {'sim_options': {'name': 'pearson', 'min_support': 1, 'user_based': False}}\n",
      "MAE Best Score:       2.2881449778589533\n",
      "\n",
      "RMSE Best Parameters: {'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': False}}\n",
      "RMSE Best Score:      3.245862428148932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning - KNNWithZScore\n",
    "\n",
    "param_grid = { 'sim_options' : {'name': ['msd','pearson','pearson_baseline'], \\\n",
    "                                'min_support': [1,5], \\\n",
    "                                'user_based': [False, True]}\n",
    "             }\n",
    "\n",
    "gridsearchKNN = GridSearchCV(KNNWithZScore, param_grid, measures=['mae', 'rmse'], \\\n",
    "                                      cv=5, n_jobs=-1)\n",
    "                                    \n",
    "gridsearchKNN.fit(data)\n",
    "\n",
    "print(f'MAE Best Parameters:  {gridsearchKNN.best_params[\"mae\"]}')\n",
    "print(f'MAE Best Score:       {gridsearchKNN.best_score[\"mae\"]}\\n')\n",
    "\n",
    "print(f'RMSE Best Parameters: {gridsearchKNN.best_params[\"rmse\"]}')\n",
    "print(f'RMSE Best Score:      {gridsearchKNN.best_score[\"rmse\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6264c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Best Parameters:  {'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': False}}\n",
      "MAE Best Score:       2.297946983678618\n",
      "\n",
      "RMSE Best Parameters: {'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': False}}\n",
      "RMSE Best Score:      3.1868143548191665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning - KNNBaseLine\n",
    "\n",
    "param_grid = { 'sim_options' : {'name': ['msd','pearson','pearson_baseline'], \\\n",
    "                                'min_support': [1,5], \\\n",
    "                                'user_based': [False, True]}\n",
    "             }\n",
    "\n",
    "gridsearchKNN = GridSearchCV(KNNBaseline, param_grid, measures=['mae', 'rmse'], \\\n",
    "                                      cv=5, n_jobs=-1)\n",
    "                                    \n",
    "gridsearchKNN.fit(data)\n",
    "\n",
    "print(f'MAE Best Parameters:  {gridsearchKNN.best_params[\"mae\"]}')\n",
    "print(f'MAE Best Score:       {gridsearchKNN.best_score[\"mae\"]}\\n')\n",
    "\n",
    "print(f'RMSE Best Parameters: {gridsearchKNN.best_params[\"rmse\"]}')\n",
    "print(f'RMSE Best Score:      {gridsearchKNN.best_score[\"rmse\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9aed9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBaseline on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    3.2125  3.1877  3.1676  3.1744  3.2128  3.1910  0.0188  \n",
      "MAE (testset)     2.3123  2.3016  2.2897  2.2951  2.3186  2.3035  0.0107  \n",
      "Fit time          0.88    0.85    0.87    0.86    0.87    0.87    0.01    \n",
      "Test time         1.63    1.62    1.73    1.62    1.64    1.65    0.04    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([3.21246893, 3.18769054, 3.16760838, 3.17442845, 3.21282754]),\n",
       " 'test_mae': array([2.31230133, 2.30158412, 2.28968406, 2.29508288, 2.31860149]),\n",
       " 'fit_time': (0.8783316612243652,\n",
       "  0.8512139320373535,\n",
       "  0.8712284564971924,\n",
       "  0.8615007400512695,\n",
       "  0.8696322441101074),\n",
       " 'test_time': (1.6334702968597412,\n",
       "  1.6168849468231201,\n",
       "  1.7294089794158936,\n",
       "  1.6199464797973633,\n",
       "  1.6387641429901123)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options       = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "\n",
    "# # We'll use the famous SVD algorithm.\n",
    "algo = KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "# Run 5-fold cross-validation and print results\n",
    "cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a166e8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNWithZScore on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    3.2845  3.2520  3.2251  3.2650  3.2256  3.2505  0.0230  \n",
      "MAE (testset)     2.3623  2.3330  2.3000  2.3477  2.3166  2.3319  0.0220  \n",
      "Fit time          0.94    0.96    0.98    0.99    1.01    0.98    0.02    \n",
      "Test time         1.52    1.58    1.52    1.52    1.53    1.53    0.02    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([3.2845232 , 3.25202416, 3.22514755, 3.2650396 , 3.22559556]),\n",
       " 'test_mae': array([2.36229709, 2.33303039, 2.30004068, 2.34771501, 2.31656183]),\n",
       " 'fit_time': (0.9386410713195801,\n",
       "  0.9615628719329834,\n",
       "  0.9820506572723389,\n",
       "  0.9946200847625732,\n",
       "  1.0074794292449951),\n",
       " 'test_time': (1.520583152770996,\n",
       "  1.5758988857269287,\n",
       "  1.5187642574310303,\n",
       "  1.5171992778778076,\n",
       "  1.5323803424835205)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options       = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "\n",
    "# # We'll use the famous SVD algorithm.\n",
    "algo = KNNWithZScore(sim_options=sim_options)\n",
    "\n",
    "# Run 5-fold cross-validation and print results\n",
    "cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adc9ceb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNWithMeans on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    3.2140  3.2518  3.2572  3.1755  3.2246  3.2246  0.0294  \n",
      "MAE (testset)     2.3384  2.3719  2.3725  2.3120  2.3391  2.3468  0.0229  \n",
      "Fit time          0.88    0.89    0.89    0.89    0.89    0.89    0.00    \n",
      "Test time         1.51    1.44    1.48    1.48    1.55    1.49    0.04    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([3.21403223, 3.25183409, 3.25722537, 3.17545563, 3.22461056]),\n",
       " 'test_mae': array([2.33840747, 2.37186062, 2.37250856, 2.31202555, 2.33913234]),\n",
       " 'fit_time': (0.8810224533081055,\n",
       "  0.8936145305633545,\n",
       "  0.8942012786865234,\n",
       "  0.8901336193084717,\n",
       "  0.8906292915344238),\n",
       " 'test_time': (1.5141706466674805,\n",
       "  1.4405834674835205,\n",
       "  1.4770317077636719,\n",
       "  1.477827548980713,\n",
       "  1.5465514659881592)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options       = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "# Run 5-fold cross-validation and print results\n",
    "cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1a96199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    3.1946  3.2238  3.2219  3.1625  3.2044  3.2014  0.0223  \n",
      "MAE (testset)     2.2830  2.3001  2.2971  2.2683  2.2885  2.2874  0.0113  \n",
      "Fit time          1.04    0.95    0.95    0.93    0.95    0.96    0.04    \n",
      "Test time         1.50    1.54    1.67    1.71    1.70    1.62    0.08    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([3.1946216 , 3.2237609 , 3.22186159, 3.16249847, 3.20436995]),\n",
       " 'test_mae': array([2.28304918, 2.30013547, 2.29714311, 2.26830413, 2.28850557]),\n",
       " 'fit_time': (1.0449776649475098,\n",
       "  0.9523639678955078,\n",
       "  0.9488754272460938,\n",
       "  0.9274604320526123,\n",
       "  0.9507274627685547),\n",
       " 'test_time': (1.5018727779388428,\n",
       "  1.5440101623535156,\n",
       "  1.6671550273895264,\n",
       "  1.7094554901123047,\n",
       "  1.698007345199585)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options       = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "\n",
    "# Run 5-fold cross-validation and print results\n",
    "cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abcb5328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Unbiased Testing Performance:\n",
      "MAE:  2.2682\n",
      "RMSE: 3.1542\n",
      "MAE: 2.268191183288463, RMSE: 3.154194714423748\n"
     ]
    }
   ],
   "source": [
    "# Model fit & prediction - KNNWithMeans\n",
    "\n",
    "sim_options = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "final_model = KNNBasic(sim_options=sim_options)\n",
    "\n",
    "# Fitting the model on trainset & predicting on testset, printing test accuracy\n",
    "pred = final_model.fit(trainset).test(testset)\n",
    "\n",
    "print(f'\\nUnbiased Testing Performance:')\n",
    "print(f'MAE: {accuracy.mae(pred)}, RMSE: {accuracy.rmse(pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f9c6daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Unbiased Testing Performance:\n",
      "MAE:  2.3285\n",
      "RMSE: 3.1749\n",
      "MAE: 2.3284858250263616, RMSE: 3.1749201958799413\n"
     ]
    }
   ],
   "source": [
    "# Model fit & prediction - KNNWithMeans\n",
    "\n",
    "sim_options = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "final_model = KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "# Fitting the model on trainset & predicting on testset, printing test accuracy\n",
    "pred = final_model.fit(trainset).test(testset)\n",
    "\n",
    "print(f'\\nUnbiased Testing Performance:')\n",
    "print(f'MAE: {accuracy.mae(pred)}, RMSE: {accuracy.rmse(pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db9807cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Unbiased Testing Performance:\n",
      "MAE:  2.2837\n",
      "RMSE: 3.1444\n",
      "MAE: 2.283706795003454, RMSE: 3.144389321600955\n"
     ]
    }
   ],
   "source": [
    "# Model fit & prediction - KNNWithMeans\n",
    "\n",
    "sim_options = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "final_model = KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "# Fitting the model on trainset & predicting on testset, printing test accuracy\n",
    "pred = final_model.fit(trainset).test(testset)\n",
    "\n",
    "print(f'\\nUnbiased Testing Performance:')\n",
    "print(f'MAE: {accuracy.mae(pred)}, RMSE: {accuracy.rmse(pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d2b1aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Unbiased Testing Performance:\n",
      "MAE:  2.3103\n",
      "RMSE: 3.1937\n",
      "MAE: 2.3103283714622833, RMSE: 3.193656565289063\n"
     ]
    }
   ],
   "source": [
    "# Model fit & prediction - KNNWithMeans\n",
    "\n",
    "sim_options = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "final_model = KNNWithZScore(sim_options=sim_options)\n",
    "\n",
    "# Fitting the model on trainset & predicting on testset, printing test accuracy\n",
    "pred = final_model.fit(trainset).test(testset)\n",
    "\n",
    "print(f'\\nUnbiased Testing Performance:')\n",
    "print(f'MAE: {accuracy.mae(pred)}, RMSE: {accuracy.rmse(pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3057000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNNBasic\n",
    "\n",
    "def generate_recommendationsKNN(userID=13552, like_recommend=40, get_recommend =10):\n",
    "    \n",
    "    ''' This function generates \"get_recommend\" number of book recommendations using \n",
    "        KNNWithMeans & item based filtering. The function needs as input three \n",
    "        different parameters:\n",
    "        (1) userID i.e., userID for which recommendations need to be generated \n",
    "        (2) like_recommend i.e., number of top recommendations for the userID to be \n",
    "        considered for making recommendations \n",
    "        (3) get_recommend i.e., number of recommendations to generate for the userID\n",
    "        Default values are: userID=13552, like_recommend=5, get_recommend=10\n",
    "    '''\n",
    "    \n",
    "    # Compute item based similarity matrix\n",
    "    sim_options       = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "    similarity_matrix = KNNBasic(sim_options=sim_options).fit(trainset).\\\n",
    "                        compute_similarities() \n",
    "    \n",
    "    userID      = trainset.to_inner_uid(userID)    # converts the raw userID to innerID\n",
    "    userRatings = trainset.ur[userID]              # method .ur takes user innerID & \n",
    "                                                   # returns back user ratings\n",
    "    \n",
    "    \n",
    "    # userRatings is a list of tuples [(,),(,),(,)..]. Each tuple contains item & rating\n",
    "    # given by the user for that item. Next, the tuples will be sorted within the list \n",
    "    # in decreasing order of rating. Then top 'like_recommend' items & ratings are extracted\n",
    "    \n",
    "    temp_df = pd.DataFrame(userRatings).sort_values(by=1, ascending=False).\\\n",
    "              head(like_recommend)\n",
    "    userRatings = temp_df.to_records(index=False) \n",
    "    \n",
    "    # for each (item,rating) in top like_recommend user items, multiply the user rating for\n",
    "    # the item with the similarity score (later is obtained from item similarity_matrix) for\n",
    "    # all items. This helps calculate the weighted rating for all items. The weighted ratings \n",
    "    # are added & divided by sum of weights to estimate rating the user would give an item\n",
    "    \n",
    "    recommendations   = {}\n",
    "\n",
    "    for user_top_item, user_top_item_rating  in userRatings:\n",
    "\n",
    "        all_item_indices          =   list(pd.DataFrame(similarity_matrix)[user_top_item].index)\n",
    "        all_item_weighted_rating  =   list(pd.DataFrame(similarity_matrix)[user_top_item].values*\\\n",
    "                                          user_top_item_rating)\n",
    "        \n",
    "        all_item_weights          =   list(pd.DataFrame(similarity_matrix)[user_top_item].values)\n",
    "        \n",
    "        \n",
    "        # All items & final estimated ratings are added to a dictionary called recommendations\n",
    "        \n",
    "        for index in range(len(all_item_indices)):\n",
    "            if index in recommendations:\n",
    "                # sum of weighted ratings\n",
    "                recommendations[index] += all_item_weighted_rating[index]        \n",
    "            else:                        \n",
    "                recommendations[index]  = all_item_weighted_rating[index]\n",
    "\n",
    "    \n",
    "    for index in range(len(all_item_indices)):                               \n",
    "            if all_item_weights[index]  !=0:\n",
    "                # final ratings (sum of weighted ratings/sum of weights)\n",
    "                recommendations[index]   =recommendations[index]/\\\n",
    "                                          (all_item_weights[index]*like_recommend)\n",
    "                      \n",
    "\n",
    "    # convert dictionary recommendations to a be a list of tuples [(,),(,),(,)]\n",
    "    # with each tuple being an item & estimated rating user would give that item\n",
    "    # sort the tuples within the list to be in decreasing order of estimated ratings\n",
    "\n",
    "    temp_df = pd.Series(recommendations).reset_index().sort_values(by=0, ascending=False)\n",
    "    recommendations = list(temp_df.to_records(index=False))\n",
    "    \n",
    "    # return get_recommend number of recommedations (only return items the user \n",
    "    # has not previously rated)\n",
    "    \n",
    "    final_recommendations = []\n",
    "    count = 0\n",
    "    \n",
    "    for item, score in recommendations:\n",
    "        flag = True\n",
    "        for userItem, userRating in trainset.ur[userID]:\n",
    "            if item == userItem: \n",
    "                flag = False       # If item in recommendations has not been rated by user, \n",
    "                break              # add to final_recommendations\n",
    "        if flag == True:\n",
    "            final_recommendations.append(trainset.to_raw_iid(item)) \n",
    "            count +=1              # trainset has the items stored as inner id,  \n",
    "                                   # convert to raw id & append \n",
    "            \n",
    "        if count > get_recommend:  # Only get 'get_recommend' number of recommendations\n",
    "            break\n",
    "    \n",
    "    return(final_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "071b20f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0671693816',\n",
       " '0671024248',\n",
       " '0767905180',\n",
       " '044022473X',\n",
       " '0684195976',\n",
       " '0553096060',\n",
       " '0515120618',\n",
       " '0385492081',\n",
       " '0446603929',\n",
       " '0399501487',\n",
       " '0451124340']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendationsKNN = generate_recommendationsKNN(userID=13552, like_recommend=40, get_recommend=10)\n",
    "recommendationsKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28b76663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0671693816</td>\n",
       "      <td>Wifey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0671024248</td>\n",
       "      <td>Hearts In Atlantis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0767905180</td>\n",
       "      <td>Jemima J: A Novel About Ugly Ducklings and Swans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>044022473X</td>\n",
       "      <td>Breach of Promise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0684195976</td>\n",
       "      <td>BODY FARM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0553096060</td>\n",
       "      <td>Sein Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0515120618</td>\n",
       "      <td>Montana Sky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0385492081</td>\n",
       "      <td>Into Thin Air : A Personal Account of the Mt. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0446603929</td>\n",
       "      <td>See How They Run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0399501487</td>\n",
       "      <td>Lord of the Flies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0451124340</td>\n",
       "      <td>Different Seasons</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ISBN                                         Book-Title\n",
       "0   0671693816                                              Wifey\n",
       "1   0671024248                                 Hearts In Atlantis\n",
       "2   0767905180   Jemima J: A Novel About Ugly Ducklings and Swans\n",
       "3   044022473X                                  Breach of Promise\n",
       "4   0684195976                                          BODY FARM\n",
       "5   0553096060                                      Sein Language\n",
       "6   0515120618                                        Montana Sky\n",
       "7   0385492081  Into Thin Air : A Personal Account of the Mt. ...\n",
       "8   0446603929                                   See How They Run\n",
       "9   0399501487                                  Lord of the Flies\n",
       "10  0451124340                                  Different Seasons"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red = pd.DataFrame(recommendationsKNN,columns = ['ISBN'])\n",
    "red_ = red.merge(book, on=\"ISBN\")[['ISBN','Book-Title']]\n",
    "red_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a731635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNNBaseline\n",
    "\n",
    "def generate_recommendationsKNN(userID=13552, like_recommend=40, get_recommend =10):\n",
    "    \n",
    "    ''' This function generates \"get_recommend\" number of book recommendations using \n",
    "        KNNWithMeans & item based filtering. The function needs as input three \n",
    "        different parameters:\n",
    "        (1) userID i.e., userID for which recommendations need to be generated \n",
    "        (2) like_recommend i.e., number of top recommendations for the userID to be \n",
    "        considered for making recommendations \n",
    "        (3) get_recommend i.e., number of recommendations to generate for the userID\n",
    "        Default values are: userID=13552, like_recommend=5, get_recommend=10\n",
    "    '''\n",
    "    \n",
    "    # Compute item based similarity matrix\n",
    "    sim_options       = {'name':'pearson_baseline','min_support':5,'user_based':False}\n",
    "    similarity_matrix = KNNBaseline(sim_options=sim_options).fit(trainset).\\\n",
    "                        compute_similarities() \n",
    "    \n",
    "    userID      = trainset.to_inner_uid(userID)    # converts the raw userID to innerID\n",
    "    userRatings = trainset.ur[userID]              # method .ur takes user innerID & \n",
    "                                                   # returns back user ratings\n",
    "    \n",
    "    \n",
    "    # userRatings is a list of tuples [(,),(,),(,)..]. Each tuple contains item & rating\n",
    "    # given by the user for that item. Next, the tuples will be sorted within the list \n",
    "    # in decreasing order of rating. Then top 'like_recommend' items & ratings are extracted\n",
    "    \n",
    "    temp_df = pd.DataFrame(userRatings).sort_values(by=1, ascending=False).\\\n",
    "              head(like_recommend)\n",
    "    userRatings = temp_df.to_records(index=False) \n",
    "    \n",
    "    # for each (item,rating) in top like_recommend user items, multiply the user rating for\n",
    "    # the item with the similarity score (later is obtained from item similarity_matrix) for\n",
    "    # all items. This helps calculate the weighted rating for all items. The weighted ratings \n",
    "    # are added & divided by sum of weights to estimate rating the user would give an item\n",
    "    \n",
    "    recommendations   = {}\n",
    "\n",
    "    for user_top_item, user_top_item_rating  in userRatings:\n",
    "\n",
    "        all_item_indices          =   list(pd.DataFrame(similarity_matrix)[user_top_item].index)\n",
    "        all_item_weighted_rating  =   list(pd.DataFrame(similarity_matrix)[user_top_item].values*\\\n",
    "                                          user_top_item_rating)\n",
    "        \n",
    "        all_item_weights          =   list(pd.DataFrame(similarity_matrix)[user_top_item].values)\n",
    "        \n",
    "        \n",
    "        # All items & final estimated ratings are added to a dictionary called recommendations\n",
    "        \n",
    "        for index in range(len(all_item_indices)):\n",
    "            if index in recommendations:\n",
    "                # sum of weighted ratings\n",
    "                recommendations[index] += all_item_weighted_rating[index]        \n",
    "            else:                        \n",
    "                recommendations[index]  = all_item_weighted_rating[index]\n",
    "\n",
    "    \n",
    "    for index in range(len(all_item_indices)):                               \n",
    "            if all_item_weights[index]  !=0:\n",
    "                # final ratings (sum of weighted ratings/sum of weights)\n",
    "                recommendations[index]   =recommendations[index]/\\\n",
    "                                          (all_item_weights[index]*like_recommend)\n",
    "                      \n",
    "\n",
    "    # convert dictionary recommendations to a be a list of tuples [(,),(,),(,)]\n",
    "    # with each tuple being an item & estimated rating user would give that item\n",
    "    # sort the tuples within the list to be in decreasing order of estimated ratings\n",
    "\n",
    "    temp_df = pd.Series(recommendations).reset_index().sort_values(by=0, ascending=False)\n",
    "    recommendations = list(temp_df.to_records(index=False))\n",
    "    \n",
    "    # return get_recommend number of recommedations (only return items the user \n",
    "    # has not previously rated)\n",
    "    \n",
    "    final_recommendations = []\n",
    "    count = 0\n",
    "    \n",
    "    for item, score in recommendations:\n",
    "        flag = True\n",
    "        for userItem, userRating in trainset.ur[userID]:\n",
    "            if item == userItem: \n",
    "                flag = False       # If item in recommendations has not been rated by user, \n",
    "                break              # add to final_recommendations\n",
    "        if flag == True:\n",
    "            final_recommendations.append(trainset.to_raw_iid(item)) \n",
    "            count +=1              # trainset has the items stored as inner id,  \n",
    "                                   # convert to raw id & append \n",
    "            \n",
    "        if count > get_recommend:  # Only get 'get_recommend' number of recommendations\n",
    "            break\n",
    "    \n",
    "    return(final_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4da0df58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0671693816',\n",
       " '0385492081',\n",
       " '044022473X',\n",
       " '0446608955',\n",
       " '0767905180',\n",
       " '0399501487',\n",
       " '0553271636',\n",
       " '0515130966',\n",
       " '0385505833',\n",
       " '0345386132',\n",
       " '0345369947']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendationsKNN = generate_recommendationsKNN(userID=13552, like_recommend=40, get_recommend=10)\n",
    "recommendationsKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95fc1ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0671693816</td>\n",
       "      <td>Wifey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0385492081</td>\n",
       "      <td>Into Thin Air : A Personal Account of the Mt. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>044022473X</td>\n",
       "      <td>Breach of Promise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0446608955</td>\n",
       "      <td>A Walk to Remember</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0767905180</td>\n",
       "      <td>Jemima J: A Novel About Ugly Ducklings and Swans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0399501487</td>\n",
       "      <td>Lord of the Flies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0553271636</td>\n",
       "      <td>D Is for Deadbeat (Kinsey Millhone Mysteries (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0515130966</td>\n",
       "      <td>Riptide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0385505833</td>\n",
       "      <td>Skipping Christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0345386132</td>\n",
       "      <td>Eyes of a Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0345369947</td>\n",
       "      <td>The Mummy or Ramses the Damned</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ISBN                                         Book-Title\n",
       "0   0671693816                                              Wifey\n",
       "1   0385492081  Into Thin Air : A Personal Account of the Mt. ...\n",
       "2   044022473X                                  Breach of Promise\n",
       "3   0446608955                                 A Walk to Remember\n",
       "4   0767905180   Jemima J: A Novel About Ugly Ducklings and Swans\n",
       "5   0399501487                                  Lord of the Flies\n",
       "6   0553271636  D Is for Deadbeat (Kinsey Millhone Mysteries (...\n",
       "7   0515130966                                            Riptide\n",
       "8   0385505833                                 Skipping Christmas\n",
       "9   0345386132                                    Eyes of a Child\n",
       "10  0345369947                     The Mummy or Ramses the Damned"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red = pd.DataFrame(recommendationsKNN,columns = ['ISBN'])\n",
    "red_ = red.merge(book, on=\"ISBN\")[['ISBN','Book-Title']]\n",
    "red_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73c62a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNNWithMeans\n",
    "\n",
    "def generate_recommendationsKNN(userID=13552, like_recommend=40, get_recommend =10):\n",
    "    \n",
    "    ''' This function generates \"get_recommend\" number of book recommendations using \n",
    "        KNNWithMeans & item based filtering. The function needs as input three \n",
    "        different parameters:\n",
    "        (1) userID i.e., userID for which recommendations need to be generated \n",
    "        (2) like_recommend i.e., number of top recommendations for the userID to be \n",
    "        considered for making recommendations \n",
    "        (3) get_recommend i.e., number of recommendations to generate for the userID\n",
    "        Default values are: userID=13552, like_recommend=5, get_recommend=10\n",
    "    '''\n",
    "    \n",
    "    # Compute item based similarity matrix\n",
    "    sim_options       = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "    similarity_matrix = KNNWithMeans(sim_options=sim_options).fit(trainset).\\\n",
    "                        compute_similarities() \n",
    "    \n",
    "    userID      = trainset.to_inner_uid(userID)    # converts the raw userID to innerID\n",
    "    userRatings = trainset.ur[userID]              # method .ur takes user innerID & \n",
    "                                                   # returns back user ratings\n",
    "    \n",
    "    \n",
    "    # userRatings is a list of tuples [(,),(,),(,)..]. Each tuple contains item & rating\n",
    "    # given by the user for that item. Next, the tuples will be sorted within the list \n",
    "    # in decreasing order of rating. Then top 'like_recommend' items & ratings are extracted\n",
    "    \n",
    "    temp_df = pd.DataFrame(userRatings).sort_values(by=1, ascending=False).\\\n",
    "              head(like_recommend)\n",
    "    userRatings = temp_df.to_records(index=False) \n",
    "    \n",
    "    # for each (item,rating) in top like_recommend user items, multiply the user rating for\n",
    "    # the item with the similarity score (later is obtained from item similarity_matrix) for\n",
    "    # all items. This helps calculate the weighted rating for all items. The weighted ratings \n",
    "    # are added & divided by sum of weights to estimate rating the user would give an item\n",
    "    \n",
    "    recommendations   = {}\n",
    "\n",
    "    for user_top_item, user_top_item_rating  in userRatings:\n",
    "\n",
    "        all_item_indices          =   list(pd.DataFrame(similarity_matrix)[user_top_item].index)\n",
    "        all_item_weighted_rating  =   list(pd.DataFrame(similarity_matrix)[user_top_item].values*\\\n",
    "                                          user_top_item_rating)\n",
    "        \n",
    "        all_item_weights          =   list(pd.DataFrame(similarity_matrix)[user_top_item].values)\n",
    "        \n",
    "        \n",
    "        # All items & final estimated ratings are added to a dictionary called recommendations\n",
    "        \n",
    "        for index in range(len(all_item_indices)):\n",
    "            if index in recommendations:\n",
    "                # sum of weighted ratings\n",
    "                recommendations[index] += all_item_weighted_rating[index]        \n",
    "            else:                        \n",
    "                recommendations[index]  = all_item_weighted_rating[index]\n",
    "\n",
    "    \n",
    "    for index in range(len(all_item_indices)):                               \n",
    "            if all_item_weights[index]  !=0:\n",
    "                # final ratings (sum of weighted ratings/sum of weights)\n",
    "                recommendations[index]   =recommendations[index]/\\\n",
    "                                          (all_item_weights[index]*like_recommend)\n",
    "                      \n",
    "\n",
    "    # convert dictionary recommendations to a be a list of tuples [(,),(,),(,)]\n",
    "    # with each tuple being an item & estimated rating user would give that item\n",
    "    # sort the tuples within the list to be in decreasing order of estimated ratings\n",
    "\n",
    "    temp_df = pd.Series(recommendations).reset_index().sort_values(by=0, ascending=False)\n",
    "    recommendations = list(temp_df.to_records(index=False))\n",
    "    \n",
    "    # return get_recommend number of recommedations (only return items the user \n",
    "    # has not previously rated)\n",
    "    \n",
    "    final_recommendations = []\n",
    "    count = 0\n",
    "    \n",
    "    for item, score in recommendations:\n",
    "        flag = True\n",
    "        for userItem, userRating in trainset.ur[userID]:\n",
    "            if item == userItem: \n",
    "                flag = False       # If item in recommendations has not been rated by user, \n",
    "                break              # add to final_recommendations\n",
    "        if flag == True:\n",
    "            final_recommendations.append(trainset.to_raw_iid(item)) \n",
    "            count +=1              # trainset has the items stored as inner id,  \n",
    "                                   # convert to raw id & append \n",
    "            \n",
    "        if count > get_recommend:  # Only get 'get_recommend' number of recommendations\n",
    "            break\n",
    "    \n",
    "    return(final_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a13eba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0671693816',\n",
       " '0671024248',\n",
       " '0767905180',\n",
       " '044022473X',\n",
       " '0684195976',\n",
       " '0553096060',\n",
       " '0515120618',\n",
       " '0385492081',\n",
       " '0446603929',\n",
       " '0399501487',\n",
       " '0451124340']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendationsKNN = generate_recommendationsKNN(userID=13552, like_recommend=40, get_recommend=10)\n",
    "recommendationsKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d3e8b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0671693816</td>\n",
       "      <td>Wifey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0671024248</td>\n",
       "      <td>Hearts In Atlantis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0767905180</td>\n",
       "      <td>Jemima J: A Novel About Ugly Ducklings and Swans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>044022473X</td>\n",
       "      <td>Breach of Promise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0684195976</td>\n",
       "      <td>BODY FARM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0553096060</td>\n",
       "      <td>Sein Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0515120618</td>\n",
       "      <td>Montana Sky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0385492081</td>\n",
       "      <td>Into Thin Air : A Personal Account of the Mt. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0446603929</td>\n",
       "      <td>See How They Run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0399501487</td>\n",
       "      <td>Lord of the Flies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0451124340</td>\n",
       "      <td>Different Seasons</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ISBN                                         Book-Title\n",
       "0   0671693816                                              Wifey\n",
       "1   0671024248                                 Hearts In Atlantis\n",
       "2   0767905180   Jemima J: A Novel About Ugly Ducklings and Swans\n",
       "3   044022473X                                  Breach of Promise\n",
       "4   0684195976                                          BODY FARM\n",
       "5   0553096060                                      Sein Language\n",
       "6   0515120618                                        Montana Sky\n",
       "7   0385492081  Into Thin Air : A Personal Account of the Mt. ...\n",
       "8   0446603929                                   See How They Run\n",
       "9   0399501487                                  Lord of the Flies\n",
       "10  0451124340                                  Different Seasons"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red = pd.DataFrame(recommendationsKNN,columns = ['ISBN'])\n",
    "red_ = red.merge(book, on=\"ISBN\")[['ISBN','Book-Title']]\n",
    "red_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1a31a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = rating['ISBN'].unique()\n",
    "iids = rating.loc[rating['User-ID']==13552, 'ISBN']\n",
    "book_to_predict = np.setdiff1d(unique_ids,iids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86a7c093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0552143774</td>\n",
       "      <td>Horse Whisperer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0446671002</td>\n",
       "      <td>The Celestine Prophecy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>042510107X</td>\n",
       "      <td>Red Storm Rising</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0671886665</td>\n",
       "      <td>A Cry In The Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>067189109X</td>\n",
       "      <td>The Blessing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0671534742</td>\n",
       "      <td>Music in the Night (Logan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0515132136</td>\n",
       "      <td>The Jury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0671873202</td>\n",
       "      <td>Hidden Jewel (Landry)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0553250531</td>\n",
       "      <td>The Valley of Horses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0425116840</td>\n",
       "      <td>The Cardinal of the Kremlin (Jack Ryan Novels)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                      Book-Title\n",
       "0  0552143774                                 Horse Whisperer\n",
       "1  0446671002                          The Celestine Prophecy\n",
       "2  042510107X                                Red Storm Rising\n",
       "3  0671886665                              A Cry In The Night\n",
       "4  067189109X                                    The Blessing\n",
       "5  0671534742                      Music in the Night (Logan)\n",
       "6  0515132136                                        The Jury\n",
       "7  0671873202                           Hidden Jewel (Landry)\n",
       "8  0553250531                            The Valley of Horses\n",
       "9  0425116840  The Cardinal of the Kremlin (Jack Ryan Novels)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options       = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "\n",
    "# # We'll use KNNWIthMeans\n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "\n",
    "algo.fit(trainset).test(testset)\n",
    "my_recs = []\n",
    "for iid in book_to_predict:\n",
    "    my_recs.append((iid, algo.predict(uid=13552,iid=iid).est))\n",
    "# rating = rating.merge(book, on=\"ISBN\")[['User-ID','ISBN','Book-Rating','Book-Title']] # merging with the book dataframe\n",
    "# rating  \n",
    "reco = pd.DataFrame(my_recs, columns=['ISBN', 'predictions']).sort_values('predictions', ascending=False).head(10)\n",
    "reco = reco.merge(book, on=\"ISBN\")[['ISBN','Book-Title']]\n",
    "reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e962b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0552143774</td>\n",
       "      <td>Horse Whisperer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1844262553</td>\n",
       "      <td>Free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0553348981</td>\n",
       "      <td>Jitterbug Perfume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0064471047</td>\n",
       "      <td>The Lion, the Witch, and the Wardrobe (The Chr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0590353403</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (Book 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0812548051</td>\n",
       "      <td>Wizard's First Rule (Sword of Truth, Book 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0385424736</td>\n",
       "      <td>The Rainmaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0439136350</td>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban (Book 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0452283442</td>\n",
       "      <td>The Darwin Awards: Evolution in Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0811801802</td>\n",
       "      <td>Sabine's Notebook: In Which the Extraordinary ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                         Book-Title\n",
       "0  0552143774                                    Horse Whisperer\n",
       "1  1844262553                                               Free\n",
       "2  0553348981                                  Jitterbug Perfume\n",
       "3  0064471047  The Lion, the Witch, and the Wardrobe (The Chr...\n",
       "4  0590353403     Harry Potter and the Sorcerer's Stone (Book 1)\n",
       "5  0812548051       Wizard's First Rule (Sword of Truth, Book 1)\n",
       "6  0385424736                                      The Rainmaker\n",
       "7  0439136350  Harry Potter and the Prisoner of Azkaban (Book 3)\n",
       "8  0452283442             The Darwin Awards: Evolution in Action\n",
       "9  0811801802  Sabine's Notebook: In Which the Extraordinary ..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options       = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "\n",
    "# # We'll use KNNWIthMeans\n",
    "algo = KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "algo.fit(trainset).test(testset)\n",
    "my_recs = []\n",
    "for iid in book_to_predict:\n",
    "    my_recs.append((iid, algo.predict(uid=13552,iid=iid).est))\n",
    "# rating = rating.merge(book, on=\"ISBN\")[['User-ID','ISBN','Book-Rating','Book-Title']] # merging with the book dataframe\n",
    "# rating  \n",
    "reco = pd.DataFrame(my_recs, columns=['ISBN', 'predictions']).sort_values('predictions', ascending=False).head(10)\n",
    "reco = reco.merge(book, on=\"ISBN\")[['ISBN','Book-Title']]\n",
    "reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0916110c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
