{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ded6b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data preparation & visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"png\"\n",
    "\n",
    "# Ignore printing warnings for general readability\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# pip install scikit-surprise\n",
    "# Importing libraries for model building & evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from surprise import KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline\n",
    "from surprise import accuracy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad1c63aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset \n",
    "def loaddata(filename):\n",
    "    df = pd.read_csv(f'{filename}.csv',sep=';',error_bad_lines=False,warn_bad_lines=False,encoding='latin-1')\n",
    "    return df\n",
    "\n",
    "book   = loaddata(\"../dataset/BX-Books\")\n",
    "user   = loaddata(\"../dataset/BX-Users\")\n",
    "rating = loaddata(\"../dataset/BX-Book-Ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "863e1e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>277427</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>277427</td>\n",
       "      <td>006092988X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>277427</td>\n",
       "      <td>0060930535</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>277427</td>\n",
       "      <td>0060932139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>277427</td>\n",
       "      <td>0060934417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147440</th>\n",
       "      <td>275970</td>\n",
       "      <td>1400031354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147441</th>\n",
       "      <td>275970</td>\n",
       "      <td>1400031362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147470</th>\n",
       "      <td>275970</td>\n",
       "      <td>1558744606</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147517</th>\n",
       "      <td>275970</td>\n",
       "      <td>1573229725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147584</th>\n",
       "      <td>275970</td>\n",
       "      <td>1853260010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81431 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         User-ID        ISBN  Book-Rating\n",
       "1456      277427  002542730X           10\n",
       "1468      277427  006092988X            0\n",
       "1469      277427  0060930535            0\n",
       "1470      277427  0060932139            0\n",
       "1471      277427  0060934417            0\n",
       "...          ...         ...          ...\n",
       "1147440   275970  1400031354            0\n",
       "1147441   275970  1400031362            0\n",
       "1147470   275970  1558744606            0\n",
       "1147517   275970  1573229725            0\n",
       "1147584   275970  1853260010            0\n",
       "\n",
       "[81431 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_users = rating['User-ID'].value_counts().reset_index().\\\n",
    "               rename({'Index':'User-ID','User-ID':'Rating'}, axis=1)\n",
    "rating_books = rating['ISBN'].value_counts().reset_index().\\\n",
    "               rename({'Index':'ISBN','ISBN':'Rating'}, axis=1)\n",
    "# In order to avoid rating bias & for making good recommendations, limit the dataset to only those\n",
    "# users that have made at least 250 ratings & books that have received at least 50 ratings\n",
    "\n",
    "rating = rating[rating['User-ID'].isin(rating_users[rating_users['Rating']>=250]['index'])]\n",
    "rating = rating[rating['ISBN'].isin(rating_books[rating_books['Rating']>=50]['index'])]\n",
    "\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "acc1c4fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>277427</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>10</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3363</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>0</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11676</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>6</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12538</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>10</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13552</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>0</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80889</th>\n",
       "      <td>234828</td>\n",
       "      <td>0345333926</td>\n",
       "      <td>8</td>\n",
       "      <td>Ringworld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80890</th>\n",
       "      <td>236283</td>\n",
       "      <td>0345333926</td>\n",
       "      <td>0</td>\n",
       "      <td>Ringworld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80891</th>\n",
       "      <td>249628</td>\n",
       "      <td>0345333926</td>\n",
       "      <td>0</td>\n",
       "      <td>Ringworld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80892</th>\n",
       "      <td>261829</td>\n",
       "      <td>0345333926</td>\n",
       "      <td>0</td>\n",
       "      <td>Ringworld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80893</th>\n",
       "      <td>264321</td>\n",
       "      <td>0345333926</td>\n",
       "      <td>8</td>\n",
       "      <td>Ringworld</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80894 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       User-ID        ISBN  Book-Rating  \\\n",
       "0       277427  002542730X           10   \n",
       "1         3363  002542730X            0   \n",
       "2        11676  002542730X            6   \n",
       "3        12538  002542730X           10   \n",
       "4        13552  002542730X            0   \n",
       "...        ...         ...          ...   \n",
       "80889   234828  0345333926            8   \n",
       "80890   236283  0345333926            0   \n",
       "80891   249628  0345333926            0   \n",
       "80892   261829  0345333926            0   \n",
       "80893   264321  0345333926            8   \n",
       "\n",
       "                                              Book-Title  \n",
       "0      Politically Correct Bedtime Stories: Modern Ta...  \n",
       "1      Politically Correct Bedtime Stories: Modern Ta...  \n",
       "2      Politically Correct Bedtime Stories: Modern Ta...  \n",
       "3      Politically Correct Bedtime Stories: Modern Ta...  \n",
       "4      Politically Correct Bedtime Stories: Modern Ta...  \n",
       "...                                                  ...  \n",
       "80889                                          Ringworld  \n",
       "80890                                          Ringworld  \n",
       "80891                                          Ringworld  \n",
       "80892                                          Ringworld  \n",
       "80893                                          Ringworld  \n",
       "\n",
       "[80894 rows x 4 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the recommendation system, it is prefered to have the book titles rather than ISBN for easier interpretation\n",
    "\n",
    "rating = rating.merge(book, on=\"ISBN\")[['User-ID','ISBN','Book-Rating','Book-Title']] # merging with the book dataframe\n",
    "rating    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd6f4bd",
   "metadata": {},
   "source": [
    "# Using surprise for data with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1c3ee5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a surprise object\n",
    "\n",
    "reader = Reader(rating_scale=(0, 10))\n",
    "# data_nonzero   = Dataset.load_from_df(ratings_explicit[['User-ID','ISBN','Book-Rating']], reader)\n",
    "data  = Dataset.load_from_df(rating[['User-ID','ISBN','Book-Rating']], reader)\n",
    "\n",
    "\n",
    "# Split the data into training & testing sets. Python's surprise documentation has the steps detailed out\n",
    "# https://surprise.readthedocs.io/en/stable/FAQ.html\n",
    "\n",
    "raw_ratings = data.raw_ratings\n",
    "random.shuffle(raw_ratings)                 # shuffle dataset\n",
    "\n",
    "threshold   = int(len(raw_ratings)*0.8)\n",
    "\n",
    "train_raw_ratings = raw_ratings[:threshold] # 80% of data is trainset\n",
    "test_raw_ratings  = raw_ratings[threshold:] # 20% of data is testset\n",
    "\n",
    "data.raw_ratings = train_raw_ratings        # data is now the trainset\n",
    "trainset         = data.build_full_trainset() \n",
    "testset          = data.construct_testset(test_raw_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9174eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying KNN (K-Nearest Neighbors) & SVD (Singluar Value decomposition) algorithms using default model parameters\n",
    "\n",
    "models=[KNNBasic(),KNNWithMeans(),KNNWithZScore(),KNNBaseline()] \n",
    "results = {}\n",
    "\n",
    "for model in models:\n",
    "    # perform 5 fold cross validation\n",
    "    # evaluation metrics: mean absolute error & root mean square error\n",
    "    CV_scores = cross_validate(model, data, measures=[\"MAE\",\"RMSE\"], cv=5, n_jobs=-1)  \n",
    "    \n",
    "    # storing the average score across the 5 fold cross validation for each model\n",
    "    result = pd.DataFrame.from_dict(CV_scores).mean(axis=0).\\\n",
    "             rename({'test_mae':'MAE', 'test_rmse': 'RMSE'})\n",
    "    results[str(model).split(\"algorithms.\")[1].split(\"object \")[0]] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fc411434",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knns.KNNWithMeans</th>\n",
       "      <td>2.349439</td>\n",
       "      <td>3.296574</td>\n",
       "      <td>0.265170</td>\n",
       "      <td>1.346878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knns.KNNBaseline</th>\n",
       "      <td>2.358011</td>\n",
       "      <td>3.311345</td>\n",
       "      <td>0.174383</td>\n",
       "      <td>1.652564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knns.KNNWithZScore</th>\n",
       "      <td>2.328952</td>\n",
       "      <td>3.335546</td>\n",
       "      <td>0.252259</td>\n",
       "      <td>1.284944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knns.KNNBasic</th>\n",
       "      <td>2.450135</td>\n",
       "      <td>3.519639</td>\n",
       "      <td>0.195459</td>\n",
       "      <td>1.521207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          MAE      RMSE  fit_time  test_time\n",
       "knns.KNNWithMeans    2.349439  3.296574  0.265170   1.346878\n",
       "knns.KNNBaseline     2.358011  3.311345  0.174383   1.652564\n",
       "knns.KNNWithZScore   2.328952  3.335546  0.252259   1.284944\n",
       "knns.KNNBasic        2.450135  3.519639  0.195459   1.521207"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df = pd.DataFrame.from_dict(results)\n",
    "print(\"Model Performance: \\n\")\n",
    "performance_df.T.sort_values(by='RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "755bf90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18651, 4)\n",
      "(62243, 4)\n"
     ]
    }
   ],
   "source": [
    "ratings_explicit=rating[rating['Book-Rating']!=0]\n",
    "ratings_implicit=rating[rating['Book-Rating']==0]\n",
    "print(ratings_explicit.shape)\n",
    "print(ratings_implicit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b8085475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Best Parameters:  {'sim_options': {'name': 'pearson', 'min_support': 1, 'user_based': False}}\n",
      "MAE Best Score:       2.328159523296675\n",
      "\n",
      "RMSE Best Parameters: {'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': False}}\n",
      "RMSE Best Score:      3.2297379861789617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning - KNNWithMeans\n",
    "\n",
    "param_grid = { 'sim_options' : {'name': ['msd','pearson','pearson_baseline'], \\\n",
    "                                'min_support': [1,5], \\\n",
    "                                'user_based': [False, True]}\n",
    "             }\n",
    "\n",
    "gridsearchKNNWithMeans = GridSearchCV(KNNWithMeans, param_grid, measures=['mae', 'rmse'], \\\n",
    "                                      cv=5, n_jobs=-1)\n",
    "                                    \n",
    "gridsearchKNNWithMeans.fit(data)\n",
    "\n",
    "print(f'MAE Best Parameters:  {gridsearchKNNWithMeans.best_params[\"mae\"]}')\n",
    "print(f'MAE Best Score:       {gridsearchKNNWithMeans.best_score[\"mae\"]}\\n')\n",
    "\n",
    "print(f'RMSE Best Parameters: {gridsearchKNNWithMeans.best_params[\"rmse\"]}')\n",
    "print(f'RMSE Best Score:      {gridsearchKNNWithMeans.best_score[\"rmse\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a56e8e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Best Parameters:  {'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': False}}\n",
      "MAE Best Score:       2.2900785392890084\n",
      "\n",
      "RMSE Best Parameters: {'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': False}}\n",
      "RMSE Best Score:      3.2067294995515474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning - KNNBasic\n",
    "\n",
    "param_grid = { 'sim_options' : {'name': ['msd','pearson','pearson_baseline'], \\\n",
    "                                'min_support': [1,5], \\\n",
    "                                'user_based': [False, True]}\n",
    "             }\n",
    "\n",
    "gridsearchKNNBasic = GridSearchCV(KNNBasic, param_grid, measures=['mae', 'rmse'], \\\n",
    "                                      cv=5, n_jobs=-1)\n",
    "                                    \n",
    "gridsearchKNNBasic.fit(data)\n",
    "\n",
    "print(f'MAE Best Parameters:  {gridsearchKNNBasic.best_params[\"mae\"]}')\n",
    "print(f'MAE Best Score:       {gridsearchKNNBasic.best_score[\"mae\"]}\\n')\n",
    "\n",
    "print(f'RMSE Best Parameters: {gridsearchKNNBasic.best_params[\"rmse\"]}')\n",
    "print(f'RMSE Best Score:      {gridsearchKNNBasic.best_score[\"rmse\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b7002b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Best Parameters:  {'sim_options': {'name': 'pearson', 'min_support': 1, 'user_based': False}}\n",
      "MAE Best Score:       2.2949738774729864\n",
      "\n",
      "RMSE Best Parameters: {'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': False}}\n",
      "RMSE Best Score:      3.24857409478862\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning - KNNWithZScore\n",
    "\n",
    "param_grid = { 'sim_options' : {'name': ['msd','pearson','pearson_baseline'], \\\n",
    "                                'min_support': [1,5], \\\n",
    "                                'user_based': [False, True]}\n",
    "             }\n",
    "\n",
    "gridsearchKNN = GridSearchCV(KNNWithZScore, param_grid, measures=['mae', 'rmse'], \\\n",
    "                                      cv=5, n_jobs=-1)\n",
    "                                    \n",
    "gridsearchKNN.fit(data)\n",
    "\n",
    "print(f'MAE Best Parameters:  {gridsearchKNN.best_params[\"mae\"]}')\n",
    "print(f'MAE Best Score:       {gridsearchKNN.best_score[\"mae\"]}\\n')\n",
    "\n",
    "print(f'RMSE Best Parameters: {gridsearchKNN.best_params[\"rmse\"]}')\n",
    "print(f'RMSE Best Score:      {gridsearchKNN.best_score[\"rmse\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d6264c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Best Parameters:  {'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': False}}\n",
      "MAE Best Score:       2.2992449803906014\n",
      "\n",
      "RMSE Best Parameters: {'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': False}}\n",
      "RMSE Best Score:      3.190976980282428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning - KNNBaseLine\n",
    "\n",
    "param_grid = { 'sim_options' : {'name': ['msd','pearson','pearson_baseline'], \\\n",
    "                                'min_support': [1,5], \\\n",
    "                                'user_based': [False, True]}\n",
    "             }\n",
    "\n",
    "gridsearchKNN = GridSearchCV(KNNBaseline, param_grid, measures=['mae', 'rmse'], \\\n",
    "                                      cv=5, n_jobs=-1)\n",
    "                                    \n",
    "gridsearchKNN.fit(data)\n",
    "\n",
    "print(f'MAE Best Parameters:  {gridsearchKNN.best_params[\"mae\"]}')\n",
    "print(f'MAE Best Score:       {gridsearchKNN.best_score[\"mae\"]}\\n')\n",
    "\n",
    "print(f'RMSE Best Parameters: {gridsearchKNN.best_params[\"rmse\"]}')\n",
    "print(f'RMSE Best Score:      {gridsearchKNN.best_score[\"rmse\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f9aed9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBaseline on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    3.1966  3.2084  3.2088  3.1815  3.1867  3.1964  0.0111  \n",
      "MAE (testset)     2.3048  2.3030  2.3164  2.2998  2.2869  2.3022  0.0095  \n",
      "Fit time          1.20    1.26    1.16    1.12    1.15    1.18    0.05    \n",
      "Test time         2.69    2.31    2.53    2.44    2.57    2.51    0.13    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([3.19657797, 3.20841191, 3.20876416, 3.18147694, 3.18665873]),\n",
       " 'test_mae': array([2.30483466, 2.30301612, 2.31637308, 2.2998013 , 2.28685835]),\n",
       " 'fit_time': (1.2038657665252686,\n",
       "  1.2563040256500244,\n",
       "  1.1595892906188965,\n",
       "  1.1202661991119385,\n",
       "  1.1486485004425049),\n",
       " 'test_time': (2.6873462200164795,\n",
       "  2.3077168464660645,\n",
       "  2.5339362621307373,\n",
       "  2.4368560314178467,\n",
       "  2.569251775741577)}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options       = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "\n",
    "# # We'll use the famous SVD algorithm.\n",
    "algo = KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "# Run 5-fold cross-validation and print results\n",
    "cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a166e8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNWithZScore on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    3.2376  3.2940  3.2159  3.2537  3.2768  3.2556  0.0277  \n",
      "MAE (testset)     2.3245  2.3495  2.3082  2.3387  2.3512  2.3344  0.0162  \n",
      "Fit time          1.31    1.38    1.29    1.33    1.42    1.35    0.05    \n",
      "Test time         2.41    2.33    2.45    2.34    2.19    2.35    0.09    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([3.23758681, 3.29400597, 3.21589022, 3.25367234, 3.27684298]),\n",
       " 'test_mae': array([2.32454364, 2.34945436, 2.30815437, 2.33871177, 2.35122158]),\n",
       " 'fit_time': (1.312831163406372,\n",
       "  1.3754403591156006,\n",
       "  1.291945457458496,\n",
       "  1.3294925689697266,\n",
       "  1.4206109046936035),\n",
       " 'test_time': (2.414608955383301,\n",
       "  2.329281806945801,\n",
       "  2.447754383087158,\n",
       "  2.342407464981079,\n",
       "  2.1940677165985107)}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options       = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "\n",
    "# # We'll use the famous SVD algorithm.\n",
    "algo = KNNWithZScore(sim_options=sim_options)\n",
    "\n",
    "# Run 5-fold cross-validation and print results\n",
    "cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "adc9ceb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNWithMeans on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    3.2387  3.2343  3.2328  3.1973  3.2797  3.2366  0.0262  \n",
      "MAE (testset)     2.3609  2.3454  2.3463  2.3214  2.3860  2.3520  0.0212  \n",
      "Fit time          1.32    1.23    1.31    1.21    1.28    1.27    0.04    \n",
      "Test time         2.24    2.22    2.38    2.30    2.18    2.26    0.07    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([3.2386903 , 3.23432256, 3.23277135, 3.19730332, 3.27970771]),\n",
       " 'test_mae': array([2.3608897 , 2.34538587, 2.34627883, 2.32144497, 2.38600018]),\n",
       " 'fit_time': (1.3231263160705566,\n",
       "  1.233036994934082,\n",
       "  1.3136212825775146,\n",
       "  1.213925838470459,\n",
       "  1.2805283069610596),\n",
       " 'test_time': (2.242658853530884,\n",
       "  2.215169906616211,\n",
       "  2.3848981857299805,\n",
       "  2.297032117843628,\n",
       "  2.1805920600891113)}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options       = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "# Run 5-fold cross-validation and print results\n",
    "cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f1a96199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    3.1807  3.2029  3.2216  3.2506  3.2046  3.2121  0.0232  \n",
      "MAE (testset)     2.2639  2.2765  2.2946  2.3322  2.2934  2.2921  0.0230  \n",
      "Fit time          1.14    1.34    1.21    1.27    1.25    1.24    0.07    \n",
      "Test time         2.24    2.02    2.48    2.14    2.17    2.21    0.15    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([3.18067891, 3.20289557, 3.22162532, 3.25055438, 3.2046289 ]),\n",
       " 'test_mae': array([2.26391708, 2.27645759, 2.29459285, 2.33215177, 2.29343109]),\n",
       " 'fit_time': (1.1396384239196777,\n",
       "  1.3381869792938232,\n",
       "  1.2132863998413086,\n",
       "  1.2717680931091309,\n",
       "  1.2489609718322754),\n",
       " 'test_time': (2.24420166015625,\n",
       "  2.0170700550079346,\n",
       "  2.4815609455108643,\n",
       "  2.140101194381714,\n",
       "  2.1732516288757324)}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options       = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "\n",
    "# Run 5-fold cross-validation and print results\n",
    "cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "abcb5328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Unbiased Testing Performance:\n",
      "MAE:  2.2773\n",
      "RMSE: 3.1630\n",
      "MAE: 2.2772513765486333, RMSE: 3.1629620918937933\n"
     ]
    }
   ],
   "source": [
    "# Model fit & prediction - KNNWithMeans\n",
    "\n",
    "sim_options = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "final_model = KNNBasic(sim_options=sim_options)\n",
    "\n",
    "# Fitting the model on trainset & predicting on testset, printing test accuracy\n",
    "pred = final_model.fit(trainset).test(testset)\n",
    "\n",
    "print(f'\\nUnbiased Testing Performance:')\n",
    "print(f'MAE: {accuracy.mae(pred)}, RMSE: {accuracy.rmse(pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5f9c6daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Unbiased Testing Performance:\n",
      "MAE:  2.3144\n",
      "RMSE: 3.1675\n",
      "MAE: 2.3143961631471015, RMSE: 3.1675066501332942\n"
     ]
    }
   ],
   "source": [
    "# Model fit & prediction - KNNWithMeans\n",
    "\n",
    "sim_options = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "final_model = KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "# Fitting the model on trainset & predicting on testset, printing test accuracy\n",
    "pred = final_model.fit(trainset).test(testset)\n",
    "\n",
    "print(f'\\nUnbiased Testing Performance:')\n",
    "print(f'MAE: {accuracy.mae(pred)}, RMSE: {accuracy.rmse(pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "db9807cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Unbiased Testing Performance:\n",
      "MAE:  2.2784\n",
      "RMSE: 3.1426\n",
      "MAE: 2.2783603682675535, RMSE: 3.142564161093465\n"
     ]
    }
   ],
   "source": [
    "# Model fit & prediction - KNNWithMeans\n",
    "\n",
    "sim_options = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "final_model = KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "# Fitting the model on trainset & predicting on testset, printing test accuracy\n",
    "pred = final_model.fit(trainset).test(testset)\n",
    "\n",
    "print(f'\\nUnbiased Testing Performance:')\n",
    "print(f'MAE: {accuracy.mae(pred)}, RMSE: {accuracy.rmse(pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4d2b1aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Unbiased Testing Performance:\n",
      "MAE:  2.2954\n",
      "RMSE: 3.1807\n",
      "MAE: 2.2953583090190643, RMSE: 3.180725481807555\n"
     ]
    }
   ],
   "source": [
    "# Model fit & prediction - KNNWithMeans\n",
    "\n",
    "sim_options = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "final_model = KNNWithZScore(sim_options=sim_options)\n",
    "\n",
    "# Fitting the model on trainset & predicting on testset, printing test accuracy\n",
    "pred = final_model.fit(trainset).test(testset)\n",
    "\n",
    "print(f'\\nUnbiased Testing Performance:')\n",
    "print(f'MAE: {accuracy.mae(pred)}, RMSE: {accuracy.rmse(pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e3057000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNNBasic\n",
    "\n",
    "def generate_recommendationsKNN(userID=13552, like_recommend=40, get_recommend =10):\n",
    "    \n",
    "    ''' This function generates \"get_recommend\" number of book recommendations using \n",
    "        KNNWithMeans & item based filtering. The function needs as input three \n",
    "        different parameters:\n",
    "        (1) userID i.e., userID for which recommendations need to be generated \n",
    "        (2) like_recommend i.e., number of top recommendations for the userID to be \n",
    "        considered for making recommendations \n",
    "        (3) get_recommend i.e., number of recommendations to generate for the userID\n",
    "        Default values are: userID=13552, like_recommend=5, get_recommend=10\n",
    "    '''\n",
    "    \n",
    "    # Compute item based similarity matrix\n",
    "    sim_options       = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "    similarity_matrix = KNNBasic(sim_options=sim_options).fit(trainset).\\\n",
    "                        compute_similarities() \n",
    "    \n",
    "    userID      = trainset.to_inner_uid(userID)    # converts the raw userID to innerID\n",
    "    userRatings = trainset.ur[userID]              # method .ur takes user innerID & \n",
    "                                                   # returns back user ratings\n",
    "    \n",
    "    \n",
    "    # userRatings is a list of tuples [(,),(,),(,)..]. Each tuple contains item & rating\n",
    "    # given by the user for that item. Next, the tuples will be sorted within the list \n",
    "    # in decreasing order of rating. Then top 'like_recommend' items & ratings are extracted\n",
    "    \n",
    "    temp_df = pd.DataFrame(userRatings).sort_values(by=1, ascending=False).\\\n",
    "              head(like_recommend)\n",
    "    userRatings = temp_df.to_records(index=False) \n",
    "    \n",
    "    # for each (item,rating) in top like_recommend user items, multiply the user rating for\n",
    "    # the item with the similarity score (later is obtained from item similarity_matrix) for\n",
    "    # all items. This helps calculate the weighted rating for all items. The weighted ratings \n",
    "    # are added & divided by sum of weights to estimate rating the user would give an item\n",
    "    \n",
    "    recommendations   = {}\n",
    "\n",
    "    for user_top_item, user_top_item_rating  in userRatings:\n",
    "\n",
    "        all_item_indices          =   list(pd.DataFrame(similarity_matrix)[user_top_item].index)\n",
    "        all_item_weighted_rating  =   list(pd.DataFrame(similarity_matrix)[user_top_item].values*\\\n",
    "                                          user_top_item_rating)\n",
    "        \n",
    "        all_item_weights          =   list(pd.DataFrame(similarity_matrix)[user_top_item].values)\n",
    "        \n",
    "        \n",
    "        # All items & final estimated ratings are added to a dictionary called recommendations\n",
    "        \n",
    "        for index in range(len(all_item_indices)):\n",
    "            if index in recommendations:\n",
    "                # sum of weighted ratings\n",
    "                recommendations[index] += all_item_weighted_rating[index]        \n",
    "            else:                        \n",
    "                recommendations[index]  = all_item_weighted_rating[index]\n",
    "\n",
    "    \n",
    "    for index in range(len(all_item_indices)):                               \n",
    "            if all_item_weights[index]  !=0:\n",
    "                # final ratings (sum of weighted ratings/sum of weights)\n",
    "                recommendations[index]   =recommendations[index]/\\\n",
    "                                          (all_item_weights[index]*like_recommend)\n",
    "                      \n",
    "\n",
    "    # convert dictionary recommendations to a be a list of tuples [(,),(,),(,)]\n",
    "    # with each tuple being an item & estimated rating user would give that item\n",
    "    # sort the tuples within the list to be in decreasing order of estimated ratings\n",
    "\n",
    "    temp_df = pd.Series(recommendations).reset_index().sort_values(by=0, ascending=False)\n",
    "    recommendations = list(temp_df.to_records(index=False))\n",
    "    \n",
    "    # return get_recommend number of recommedations (only return items the user \n",
    "    # has not previously rated)\n",
    "    \n",
    "    final_recommendations = []\n",
    "    count = 0\n",
    "    \n",
    "    for item, score in recommendations:\n",
    "        flag = True\n",
    "        for userItem, userRating in trainset.ur[userID]:\n",
    "            if item == userItem: \n",
    "                flag = False       # If item in recommendations has not been rated by user, \n",
    "                break              # add to final_recommendations\n",
    "        if flag == True:\n",
    "            final_recommendations.append(trainset.to_raw_iid(item)) \n",
    "            count +=1              # trainset has the items stored as inner id,  \n",
    "                                   # convert to raw id & append \n",
    "            \n",
    "        if count > get_recommend:  # Only get 'get_recommend' number of recommendations\n",
    "            break\n",
    "    \n",
    "    return(final_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "071b20f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0446350982',\n",
       " '0553580388',\n",
       " '0671004530',\n",
       " '0446608955',\n",
       " '0440236053',\n",
       " '0425101452',\n",
       " '0446611085',\n",
       " '0786889551',\n",
       " '0425189031',\n",
       " '1565122968',\n",
       " '140003180X']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendationsKNN = generate_recommendationsKNN(userID=13552, like_recommend=40, get_recommend=10)\n",
    "recommendationsKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "28b76663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0446350982</td>\n",
       "      <td>Presumed Innocent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0553580388</td>\n",
       "      <td>The Patient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0671004530</td>\n",
       "      <td>On the Street Where You Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0446608955</td>\n",
       "      <td>A Walk to Remember</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0440236053</td>\n",
       "      <td>Writ of Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0425101452</td>\n",
       "      <td>Phantoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0446611085</td>\n",
       "      <td>Suzanne's Diary for Nicholas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0786889551</td>\n",
       "      <td>The Pied Piper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0425189031</td>\n",
       "      <td>Portrait in Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1565122968</td>\n",
       "      <td>Gap Creek: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>140003180X</td>\n",
       "      <td>The Kalahari Typing School for Men (No. 1 Ladi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ISBN                                         Book-Title\n",
       "0   0446350982                                  Presumed Innocent\n",
       "1   0553580388                                        The Patient\n",
       "2   0671004530                       On the Street Where You Live\n",
       "3   0446608955                                 A Walk to Remember\n",
       "4   0440236053                                  Writ of Execution\n",
       "5   0425101452                                           Phantoms\n",
       "6   0446611085                       Suzanne's Diary for Nicholas\n",
       "7   0786889551                                     The Pied Piper\n",
       "8   0425189031                                  Portrait in Death\n",
       "9   1565122968                                 Gap Creek: A Novel\n",
       "10  140003180X  The Kalahari Typing School for Men (No. 1 Ladi..."
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red = pd.DataFrame(recommendationsKNN,columns = ['ISBN'])\n",
    "red_ = red.merge(book, on=\"ISBN\")[['ISBN','Book-Title']]\n",
    "red_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9a731635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNNBaseline\n",
    "\n",
    "def generate_recommendationsKNN(userID=13552, like_recommend=40, get_recommend =10):\n",
    "    \n",
    "    ''' This function generates \"get_recommend\" number of book recommendations using \n",
    "        KNNWithMeans & item based filtering. The function needs as input three \n",
    "        different parameters:\n",
    "        (1) userID i.e., userID for which recommendations need to be generated \n",
    "        (2) like_recommend i.e., number of top recommendations for the userID to be \n",
    "        considered for making recommendations \n",
    "        (3) get_recommend i.e., number of recommendations to generate for the userID\n",
    "        Default values are: userID=13552, like_recommend=5, get_recommend=10\n",
    "    '''\n",
    "    \n",
    "    # Compute item based similarity matrix\n",
    "    sim_options       = {'name':'pearson_baseline','min_support':5,'user_based':False}\n",
    "    similarity_matrix = KNNBaseline(sim_options=sim_options).fit(trainset).\\\n",
    "                        compute_similarities() \n",
    "    \n",
    "    userID      = trainset.to_inner_uid(userID)    # converts the raw userID to innerID\n",
    "    userRatings = trainset.ur[userID]              # method .ur takes user innerID & \n",
    "                                                   # returns back user ratings\n",
    "    \n",
    "    \n",
    "    # userRatings is a list of tuples [(,),(,),(,)..]. Each tuple contains item & rating\n",
    "    # given by the user for that item. Next, the tuples will be sorted within the list \n",
    "    # in decreasing order of rating. Then top 'like_recommend' items & ratings are extracted\n",
    "    \n",
    "    temp_df = pd.DataFrame(userRatings).sort_values(by=1, ascending=False).\\\n",
    "              head(like_recommend)\n",
    "    userRatings = temp_df.to_records(index=False) \n",
    "    \n",
    "    # for each (item,rating) in top like_recommend user items, multiply the user rating for\n",
    "    # the item with the similarity score (later is obtained from item similarity_matrix) for\n",
    "    # all items. This helps calculate the weighted rating for all items. The weighted ratings \n",
    "    # are added & divided by sum of weights to estimate rating the user would give an item\n",
    "    \n",
    "    recommendations   = {}\n",
    "\n",
    "    for user_top_item, user_top_item_rating  in userRatings:\n",
    "\n",
    "        all_item_indices          =   list(pd.DataFrame(similarity_matrix)[user_top_item].index)\n",
    "        all_item_weighted_rating  =   list(pd.DataFrame(similarity_matrix)[user_top_item].values*\\\n",
    "                                          user_top_item_rating)\n",
    "        \n",
    "        all_item_weights          =   list(pd.DataFrame(similarity_matrix)[user_top_item].values)\n",
    "        \n",
    "        \n",
    "        # All items & final estimated ratings are added to a dictionary called recommendations\n",
    "        \n",
    "        for index in range(len(all_item_indices)):\n",
    "            if index in recommendations:\n",
    "                # sum of weighted ratings\n",
    "                recommendations[index] += all_item_weighted_rating[index]        \n",
    "            else:                        \n",
    "                recommendations[index]  = all_item_weighted_rating[index]\n",
    "\n",
    "    \n",
    "    for index in range(len(all_item_indices)):                               \n",
    "            if all_item_weights[index]  !=0:\n",
    "                # final ratings (sum of weighted ratings/sum of weights)\n",
    "                recommendations[index]   =recommendations[index]/\\\n",
    "                                          (all_item_weights[index]*like_recommend)\n",
    "                      \n",
    "\n",
    "    # convert dictionary recommendations to a be a list of tuples [(,),(,),(,)]\n",
    "    # with each tuple being an item & estimated rating user would give that item\n",
    "    # sort the tuples within the list to be in decreasing order of estimated ratings\n",
    "\n",
    "    temp_df = pd.Series(recommendations).reset_index().sort_values(by=0, ascending=False)\n",
    "    recommendations = list(temp_df.to_records(index=False))\n",
    "    \n",
    "    # return get_recommend number of recommedations (only return items the user \n",
    "    # has not previously rated)\n",
    "    \n",
    "    final_recommendations = []\n",
    "    count = 0\n",
    "    \n",
    "    for item, score in recommendations:\n",
    "        flag = True\n",
    "        for userItem, userRating in trainset.ur[userID]:\n",
    "            if item == userItem: \n",
    "                flag = False       # If item in recommendations has not been rated by user, \n",
    "                break              # add to final_recommendations\n",
    "        if flag == True:\n",
    "            final_recommendations.append(trainset.to_raw_iid(item)) \n",
    "            count +=1              # trainset has the items stored as inner id,  \n",
    "                                   # convert to raw id & append \n",
    "            \n",
    "        if count > get_recommend:  # Only get 'get_recommend' number of recommendations\n",
    "            break\n",
    "    \n",
    "    return(final_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4da0df58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0446608955',\n",
       " '0553580388',\n",
       " '0671004530',\n",
       " '0786889551',\n",
       " '0446611085',\n",
       " '0425189031',\n",
       " '0449003795',\n",
       " '0425178765',\n",
       " '0553561618',\n",
       " '0440166497',\n",
       " '051513287X']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendationsKNN = generate_recommendationsKNN(userID=13552, like_recommend=40, get_recommend=10)\n",
    "recommendationsKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "95fc1ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0446608955</td>\n",
       "      <td>A Walk to Remember</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0553580388</td>\n",
       "      <td>The Patient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0671004530</td>\n",
       "      <td>On the Street Where You Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0786889551</td>\n",
       "      <td>The Pied Piper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0446611085</td>\n",
       "      <td>Suzanne's Diary for Nicholas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0425189031</td>\n",
       "      <td>Portrait in Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0449003795</td>\n",
       "      <td>P Is for Peril</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0425178765</td>\n",
       "      <td>Easy Prey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0553561618</td>\n",
       "      <td>Dark Paradise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0440166497</td>\n",
       "      <td>Once in a Lifetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>051513287X</td>\n",
       "      <td>Face the Fire (Three Sisters Island Trilogy)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ISBN                                    Book-Title\n",
       "0   0446608955                            A Walk to Remember\n",
       "1   0553580388                                   The Patient\n",
       "2   0671004530                  On the Street Where You Live\n",
       "3   0786889551                                The Pied Piper\n",
       "4   0446611085                  Suzanne's Diary for Nicholas\n",
       "5   0425189031                             Portrait in Death\n",
       "6   0449003795                                P Is for Peril\n",
       "7   0425178765                                     Easy Prey\n",
       "8   0553561618                                 Dark Paradise\n",
       "9   0440166497                            Once in a Lifetime\n",
       "10  051513287X  Face the Fire (Three Sisters Island Trilogy)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red = pd.DataFrame(recommendationsKNN,columns = ['ISBN'])\n",
    "red_ = red.merge(book, on=\"ISBN\")[['ISBN','Book-Title']]\n",
    "red_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "73c62a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNNWithMeans\n",
    "\n",
    "def generate_recommendationsKNN(userID=13552, like_recommend=40, get_recommend =10):\n",
    "    \n",
    "    ''' This function generates \"get_recommend\" number of book recommendations using \n",
    "        KNNWithMeans & item based filtering. The function needs as input three \n",
    "        different parameters:\n",
    "        (1) userID i.e., userID for which recommendations need to be generated \n",
    "        (2) like_recommend i.e., number of top recommendations for the userID to be \n",
    "        considered for making recommendations \n",
    "        (3) get_recommend i.e., number of recommendations to generate for the userID\n",
    "        Default values are: userID=13552, like_recommend=5, get_recommend=10\n",
    "    '''\n",
    "    \n",
    "    # Compute item based similarity matrix\n",
    "    sim_options       = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "    similarity_matrix = KNNWithMeans(sim_options=sim_options).fit(trainset).\\\n",
    "                        compute_similarities() \n",
    "    \n",
    "    userID      = trainset.to_inner_uid(userID)    # converts the raw userID to innerID\n",
    "    userRatings = trainset.ur[userID]              # method .ur takes user innerID & \n",
    "                                                   # returns back user ratings\n",
    "    \n",
    "    \n",
    "    # userRatings is a list of tuples [(,),(,),(,)..]. Each tuple contains item & rating\n",
    "    # given by the user for that item. Next, the tuples will be sorted within the list \n",
    "    # in decreasing order of rating. Then top 'like_recommend' items & ratings are extracted\n",
    "    \n",
    "    temp_df = pd.DataFrame(userRatings).sort_values(by=1, ascending=False).\\\n",
    "              head(like_recommend)\n",
    "    userRatings = temp_df.to_records(index=False) \n",
    "    \n",
    "    # for each (item,rating) in top like_recommend user items, multiply the user rating for\n",
    "    # the item with the similarity score (later is obtained from item similarity_matrix) for\n",
    "    # all items. This helps calculate the weighted rating for all items. The weighted ratings \n",
    "    # are added & divided by sum of weights to estimate rating the user would give an item\n",
    "    \n",
    "    recommendations   = {}\n",
    "\n",
    "    for user_top_item, user_top_item_rating  in userRatings:\n",
    "\n",
    "        all_item_indices          =   list(pd.DataFrame(similarity_matrix)[user_top_item].index)\n",
    "        all_item_weighted_rating  =   list(pd.DataFrame(similarity_matrix)[user_top_item].values*\\\n",
    "                                          user_top_item_rating)\n",
    "        \n",
    "        all_item_weights          =   list(pd.DataFrame(similarity_matrix)[user_top_item].values)\n",
    "        \n",
    "        \n",
    "        # All items & final estimated ratings are added to a dictionary called recommendations\n",
    "        \n",
    "        for index in range(len(all_item_indices)):\n",
    "            if index in recommendations:\n",
    "                # sum of weighted ratings\n",
    "                recommendations[index] += all_item_weighted_rating[index]        \n",
    "            else:                        \n",
    "                recommendations[index]  = all_item_weighted_rating[index]\n",
    "\n",
    "    \n",
    "    for index in range(len(all_item_indices)):                               \n",
    "            if all_item_weights[index]  !=0:\n",
    "                # final ratings (sum of weighted ratings/sum of weights)\n",
    "                recommendations[index]   =recommendations[index]/\\\n",
    "                                          (all_item_weights[index]*like_recommend)\n",
    "                      \n",
    "\n",
    "    # convert dictionary recommendations to a be a list of tuples [(,),(,),(,)]\n",
    "    # with each tuple being an item & estimated rating user would give that item\n",
    "    # sort the tuples within the list to be in decreasing order of estimated ratings\n",
    "\n",
    "    temp_df = pd.Series(recommendations).reset_index().sort_values(by=0, ascending=False)\n",
    "    recommendations = list(temp_df.to_records(index=False))\n",
    "    \n",
    "    # return get_recommend number of recommedations (only return items the user \n",
    "    # has not previously rated)\n",
    "    \n",
    "    final_recommendations = []\n",
    "    count = 0\n",
    "    \n",
    "    for item, score in recommendations:\n",
    "        flag = True\n",
    "        for userItem, userRating in trainset.ur[userID]:\n",
    "            if item == userItem: \n",
    "                flag = False       # If item in recommendations has not been rated by user, \n",
    "                break              # add to final_recommendations\n",
    "        if flag == True:\n",
    "            final_recommendations.append(trainset.to_raw_iid(item)) \n",
    "            count +=1              # trainset has the items stored as inner id,  \n",
    "                                   # convert to raw id & append \n",
    "            \n",
    "        if count > get_recommend:  # Only get 'get_recommend' number of recommendations\n",
    "            break\n",
    "    \n",
    "    return(final_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0a13eba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0446350982',\n",
       " '0553580388',\n",
       " '0671004530',\n",
       " '0446608955',\n",
       " '0440236053',\n",
       " '0425101452',\n",
       " '0446611085',\n",
       " '0786889551',\n",
       " '0425189031',\n",
       " '1565122968',\n",
       " '140003180X']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendationsKNN = generate_recommendationsKNN(userID=13552, like_recommend=40, get_recommend=10)\n",
    "recommendationsKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5d3e8b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0446350982</td>\n",
       "      <td>Presumed Innocent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0553580388</td>\n",
       "      <td>The Patient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0671004530</td>\n",
       "      <td>On the Street Where You Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0446608955</td>\n",
       "      <td>A Walk to Remember</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0440236053</td>\n",
       "      <td>Writ of Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0425101452</td>\n",
       "      <td>Phantoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0446611085</td>\n",
       "      <td>Suzanne's Diary for Nicholas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0786889551</td>\n",
       "      <td>The Pied Piper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0425189031</td>\n",
       "      <td>Portrait in Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1565122968</td>\n",
       "      <td>Gap Creek: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>140003180X</td>\n",
       "      <td>The Kalahari Typing School for Men (No. 1 Ladi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ISBN                                         Book-Title\n",
       "0   0446350982                                  Presumed Innocent\n",
       "1   0553580388                                        The Patient\n",
       "2   0671004530                       On the Street Where You Live\n",
       "3   0446608955                                 A Walk to Remember\n",
       "4   0440236053                                  Writ of Execution\n",
       "5   0425101452                                           Phantoms\n",
       "6   0446611085                       Suzanne's Diary for Nicholas\n",
       "7   0786889551                                     The Pied Piper\n",
       "8   0425189031                                  Portrait in Death\n",
       "9   1565122968                                 Gap Creek: A Novel\n",
       "10  140003180X  The Kalahari Typing School for Men (No. 1 Ladi..."
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red = pd.DataFrame(recommendationsKNN,columns = ['ISBN'])\n",
    "red_ = red.merge(book, on=\"ISBN\")[['ISBN','Book-Title']]\n",
    "red_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a1a31a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = rating['ISBN'].unique()\n",
    "iids = rating.loc[rating['User-ID']==13552, 'ISBN']\n",
    "book_to_predict = np.setdiff1d(unique_ids,iids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ef9829c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0590660543</td>\n",
       "      <td>Northern Lights (His Dark Materials S.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0007110928</td>\n",
       "      <td>Billy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0061096113</td>\n",
       "      <td>Mistaken Identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0812575717</td>\n",
       "      <td>Ender's Shadow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>051513225X</td>\n",
       "      <td>Pendragon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0451209907</td>\n",
       "      <td>Quentins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0140039589</td>\n",
       "      <td>Watership Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0061097861</td>\n",
       "      <td>Hunting Badger (Joe Leaphorn/Jim Chee Novels)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0515125628</td>\n",
       "      <td>The Target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0316693006</td>\n",
       "      <td>Four Blind Mice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                     Book-Title\n",
       "0  0590660543        Northern Lights (His Dark Materials S.)\n",
       "1  0007110928                                          Billy\n",
       "2  0061096113                              Mistaken Identity\n",
       "3  0812575717                                 Ender's Shadow\n",
       "4  051513225X                                      Pendragon\n",
       "5  0451209907                                       Quentins\n",
       "6  0140039589                                 Watership Down\n",
       "7  0061097861  Hunting Badger (Joe Leaphorn/Jim Chee Novels)\n",
       "8  0515125628                                     The Target\n",
       "9  0316693006                                Four Blind Mice"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options       = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "\n",
    "# # We'll use KNNWIthMeans\n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "\n",
    "algo.fit(trainset).test(testset)\n",
    "my_recs = []\n",
    "for iid in book_to_predict:\n",
    "    my_recs.append((iid, algo.predict(uid=13552,iid=iid).est))\n",
    "# rating = rating.merge(book, on=\"ISBN\")[['User-ID','ISBN','Book-Rating','Book-Title']] # merging with the book dataframe\n",
    "# rating  \n",
    "reco = pd.DataFrame(my_recs, columns=['ISBN', 'predictions']).sort_values('predictions', ascending=False).head(10)\n",
    "reco = reco.merge(book, on=\"ISBN\")[['ISBN','Book-Title']]\n",
    "reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f037b5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1844262553</td>\n",
       "      <td>Free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0618002227</td>\n",
       "      <td>The Fellowship of the Ring (The Lord of the Ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060929790</td>\n",
       "      <td>One Hundred Years of Solitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0590660543</td>\n",
       "      <td>Northern Lights (His Dark Materials S.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0590353403</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (Book 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3442541751</td>\n",
       "      <td>Russendisko.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0007110928</td>\n",
       "      <td>Billy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0811801802</td>\n",
       "      <td>Sabine's Notebook: In Which the Extraordinary ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0670894605</td>\n",
       "      <td>The Secret Life of Bees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0670868361</td>\n",
       "      <td>Desperation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                         Book-Title\n",
       "0  1844262553                                               Free\n",
       "1  0618002227  The Fellowship of the Ring (The Lord of the Ri...\n",
       "2  0060929790                      One Hundred Years of Solitude\n",
       "3  0590660543            Northern Lights (His Dark Materials S.)\n",
       "4  0590353403     Harry Potter and the Sorcerer's Stone (Book 1)\n",
       "5  3442541751                                       Russendisko.\n",
       "6  0007110928                                              Billy\n",
       "7  0811801802  Sabine's Notebook: In Which the Extraordinary ...\n",
       "8  0670894605                            The Secret Life of Bees\n",
       "9  0670868361                                        Desperation"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options       = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "\n",
    "# # We'll use KNNWIthMeans\n",
    "algo = KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "algo.fit(trainset).test(testset)\n",
    "my_recs = []\n",
    "for iid in book_to_predict:\n",
    "    my_recs.append((iid, algo.predict(uid=13552,iid=iid).est))\n",
    "# rating = rating.merge(book, on=\"ISBN\")[['User-ID','ISBN','Book-Rating','Book-Title']] # merging with the book dataframe\n",
    "# rating  \n",
    "reco = pd.DataFrame(my_recs, columns=['ISBN', 'predictions']).sort_values('predictions', ascending=False).head(10)\n",
    "reco = reco.merge(book, on=\"ISBN\")[['ISBN','Book-Title']]\n",
    "reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05c0f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
